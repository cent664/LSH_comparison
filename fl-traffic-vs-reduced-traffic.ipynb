{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2573009,"sourceType":"datasetVersion","datasetId":1562259}],"dockerImageVersionId":30120,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import keras\nfrom keras.layers import *\nfrom keras.activations import *\nfrom keras.models import *\nfrom keras.utils import *\nimport keras.backend as K\nfrom keras.initializers import glorot_uniform\nfrom keras.preprocessing import image\nfrom keras.datasets import mnist\nfrom keras.losses import *\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, Callback\nimport tensorflow as tf\n\nimport numpy as np\nimport os\nimport random\nfrom timeit import default_timer as timer\nimport time\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle","metadata":{"execution":{"iopub.status.busy":"2021-11-03T01:16:32.786582Z","iopub.execute_input":"2021-11-03T01:16:32.786991Z","iopub.status.idle":"2021-11-03T01:16:34.669912Z","shell.execute_reply.started":"2021-11-03T01:16:32.786892Z","shell.execute_reply":"2021-11-03T01:16:34.669057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (756, 434)\n# (252, 145)\nimg_dim = (145, 252)\nimg_shape = (145, 252, 3)\nepoch_number = 50\nbatches = 16\n\npath = \"./full_dataset/\"\nif not os.path.exists(path):\n    os.makedirs(path)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T01:16:34.671521Z","iopub.execute_input":"2021-11-03T01:16:34.67188Z","iopub.status.idle":"2021-11-03T01:16:34.677738Z","shell.execute_reply.started":"2021-11-03T01:16:34.671841Z","shell.execute_reply":"2021-11-03T01:16:34.676725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Base dataset**\n---","metadata":{"id":"ZbS206mvfd8u"}},{"cell_type":"code","source":"# Callback class for time history\nclass TimingCallback(keras.callbacks.Callback):\n    def __init__(self, logs={}):\n        self.logs=[]\n    def on_epoch_begin(self, epoch, logs={}):\n        self.starttime = timer()\n    def on_epoch_end(self, epoch, logs={}):\n        self.logs.append(timer()-self.starttime)","metadata":{"id":"E_5Qe9Ve9DV1","execution":{"iopub.status.busy":"2021-11-03T01:16:34.680109Z","iopub.execute_input":"2021-11-03T01:16:34.680468Z","iopub.status.idle":"2021-11-03T01:16:34.688832Z","shell.execute_reply.started":"2021-11-03T01:16:34.680431Z","shell.execute_reply":"2021-11-03T01:16:34.68778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(img_shape, classes=4):\n  # Implementing LeNet-5 with Keras functional API\n  input_img = keras.Input(shape=(img_shape))\n\n  x = Conv2D(filters=6, kernel_size=5, strides=1, activation='relu')(input_img)  # conv1\n  x = Dropout(0.2)(x)  \n  x = MaxPooling2D(pool_size=2, strides=2)(x)  # pooling1\n\n  x = Conv2D(filters=16, kernel_size=5, strides=1, activation='relu')(x)  # conv2\n  x = Dropout(0.2)(x)\n  x = MaxPooling2D(pool_size=2, strides=2)(x)  # pooling2\n\n  x = Flatten()(x)  # Flatten\n  x = Dense(units=120, activation='relu')(x)  # FCC1\n  x = Dense(units=84, activation='relu')(x)  # FCC2\n  class_prob = Dense(units = classes, activation='softmax')(x)  # FCC3/output\n\n  model_train = Model(input_img, class_prob)\n  \n  return model_train","metadata":{"id":"H9U7-z0xy0M9","execution":{"iopub.status.busy":"2021-11-03T01:16:34.692028Z","iopub.execute_input":"2021-11-03T01:16:34.692328Z","iopub.status.idle":"2021-11-03T01:16:34.70278Z","shell.execute_reply.started":"2021-11-03T01:16:34.692303Z","shell.execute_reply":"2021-11-03T01:16:34.701842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_block(X, f, filters, stage, block):\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    # Retrieve Filters\n    F1, F2, F3 = filters\n\n    # Save the input value. We'll need this later to add back to the main path. \n    X_shortcut = X\n\n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n\ndef convolutional_block(X, f, filters, stage, block, s = 2):\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    \n    ##### SHORTCUT PATH ####\n    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n\ndef get_resnet_model(input_shape=img_shape, classes=4):   \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    # X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n    # Stage 3\n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    # X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    # X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    # Stage 4\n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    # X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    # X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    # X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    # X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    # Stage 5\n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    # X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    # Avg pool.\n    X = GlobalAveragePooling2D(name='global_avg_pool')(X)\n\n    # output layer\n    # X = Flatten()(X)\n    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet')\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-03T01:16:34.705872Z","iopub.execute_input":"2021-11-03T01:16:34.706164Z","iopub.status.idle":"2021-11-03T01:16:34.733214Z","shell.execute_reply.started":"2021-11-03T01:16:34.706134Z","shell.execute_reply":"2021-11-03T01:16:34.732285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = image.ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\ntrain_generator = datagen.flow_from_directory(\n    directory='../input/trafficclassified/archive/traffic classified/full_dataset',\n    target_size=img_dim,\n    color_mode='rgb',\n    class_mode='categorical',\n    subset='training')\n\nvalidation_generator = datagen.flow_from_directory(\n    directory='../input/trafficclassified/archive/traffic classified/full_dataset',\n    target_size=img_dim,\n    color_mode='rgb',\n    class_mode='categorical',\n    subset='validation')","metadata":{"id":"VrNSBLrVy0H4","outputId":"5c37caa3-fd14-4581-807f-444ffd8cc1c1","execution":{"iopub.status.busy":"2021-11-03T01:16:34.734887Z","iopub.execute_input":"2021-11-03T01:16:34.735191Z","iopub.status.idle":"2021-11-03T01:16:35.074761Z","shell.execute_reply.started":"2021-11-03T01:16:34.735152Z","shell.execute_reply":"2021-11-03T01:16:35.073845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_base = get_model(img_shape, 4)\n# model_base = get_resnet_model((img_shape), 4)\nmodel_base.summary()","metadata":{"id":"g_H6uf60Chiu","outputId":"4248a870-d3ba-4fa8-ee2e-c3d7f79b7515","execution":{"iopub.status.busy":"2021-11-03T01:16:35.075916Z","iopub.execute_input":"2021-11-03T01:16:35.076265Z","iopub.status.idle":"2021-11-03T01:16:36.090836Z","shell.execute_reply.started":"2021-11-03T01:16:35.076237Z","shell.execute_reply":"2021-11-03T01:16:36.08998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model_base, show_dtype=True, show_layer_names=True, show_shapes=True, expand_nested=True, to_file='model_plot.png')","metadata":{"execution":{"iopub.status.busy":"2021-11-03T01:16:36.092255Z","iopub.execute_input":"2021-11-03T01:16:36.092612Z","iopub.status.idle":"2021-11-03T01:16:36.274599Z","shell.execute_reply.started":"2021-11-03T01:16:36.092576Z","shell.execute_reply":"2021-11-03T01:16:36.273667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\ntime_callback = TimingCallback()\nmodel_base.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\nhistory_base = model_base.fit(train_generator,\n                              epochs=epoch_number,\n                              steps_per_epoch=train_generator.n//train_generator.batch_size,\n                              validation_data=validation_generator,\n                              validation_steps=validation_generator.n//validation_generator.batch_size,\n                              callbacks = [time_callback])","metadata":{"id":"i1G83fwey0Pq","outputId":"a8f93814-8c48-40ce-80f6-adef907045e5","execution":{"iopub.status.busy":"2021-11-03T01:16:36.277516Z","iopub.execute_input":"2021-11-03T01:16:36.277763Z","iopub.status.idle":"2021-11-03T01:31:25.129136Z","shell.execute_reply.started":"2021-11-03T01:16:36.277736Z","shell.execute_reply":"2021-11-03T01:31:25.128256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking that I got the values\nprint(history_base.history.keys())\nprint(history_base.history['loss'])\nprint(history_base.history['accuracy'])\nprint(history_base.history['val_loss'])\nprint(history_base.history['val_accuracy'])","metadata":{"id":"7tGQPz1Ey0Sj","execution":{"iopub.status.busy":"2021-11-03T01:31:25.131269Z","iopub.execute_input":"2021-11-03T01:31:25.131618Z","iopub.status.idle":"2021-11-03T01:31:25.140754Z","shell.execute_reply.started":"2021-11-03T01:31:25.131578Z","shell.execute_reply":"2021-11-03T01:31:25.137504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving weights\nmodel_base.save_weights(path + 'base_weights.h5')","metadata":{"id":"t3j-GYcoyzDD","execution":{"iopub.status.busy":"2021-11-03T01:31:25.142089Z","iopub.execute_input":"2021-11-03T01:31:25.142607Z","iopub.status.idle":"2021-11-03T01:31:25.19272Z","shell.execute_reply.started":"2021-11-03T01:31:25.142548Z","shell.execute_reply":"2021-11-03T01:31:25.191872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_time = time_callback.logs\nprint(np.mean(base_time), base_time)","metadata":{"id":"SWDbhfc7v8mH","execution":{"iopub.status.busy":"2021-11-03T01:31:25.193962Z","iopub.execute_input":"2021-11-03T01:31:25.194309Z","iopub.status.idle":"2021-11-03T01:31:25.200374Z","shell.execute_reply.started":"2021-11-03T01:31:25.194276Z","shell.execute_reply":"2021-11-03T01:31:25.199548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting\nfig, (ax1, ax2) = plt.subplots(1, 2, sharex=True, figsize=(25, 10))\n\nax1.plot(history_base.history['accuracy'])\nax1.plot(history_base.history['val_accuracy'])\nax1.set_title('Accuracy over epochs')\nax1.set(xlabel='Epoch', ylabel='Accuracy')\nax1.grid()\nax1.legend(['Train', 'Validation'], loc='lower right')\n\nax2.plot(history_base.history['loss'])\nax2.plot(history_base.history['val_loss'])\nax2.set_title('Loss over epochs')\nax2.set(xlabel='Epoch', ylabel='Loss')\nax2.grid()\nax2.legend(['Train', 'Validation'], loc='upper right')\n\n\nplt.show()\nfig.savefig(path + 'Loss and Accuracy over Epochs (Base).png')","metadata":{"id":"9LnjCR7IzGGi","execution":{"iopub.status.busy":"2021-11-03T01:31:25.201665Z","iopub.execute_input":"2021-11-03T01:31:25.202243Z","iopub.status.idle":"2021-11-03T01:31:25.668877Z","shell.execute_reply.started":"2021-11-03T01:31:25.202207Z","shell.execute_reply":"2021-11-03T01:31:25.668107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reduced dataset**\n---\n","metadata":{"id":"a0fmnxDGfK7O"}},{"cell_type":"code","source":"path = \"./reduced_dataset/\"\nif not os.path.exists(path):\n    os.makedirs(path)","metadata":{"id":"DtNw3y49OKZJ","execution":{"iopub.status.busy":"2021-11-03T01:31:25.670152Z","iopub.execute_input":"2021-11-03T01:31:25.670496Z","iopub.status.idle":"2021-11-03T01:31:25.676005Z","shell.execute_reply.started":"2021-11-03T01:31:25.67046Z","shell.execute_reply":"2021-11-03T01:31:25.674359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = image.ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\ntrain_generator = datagen.flow_from_directory(\n    directory='../input/trafficclassified/archive/traffic classified/reduced_dataset',\n    target_size=img_dim,\n    color_mode='rgb',\n    class_mode='categorical',\n    subset='training')\n\nvalidation_generator = datagen.flow_from_directory(\n    directory='../input/trafficclassified/archive/traffic classified/reduced_dataset',\n    target_size=img_dim,\n    color_mode='rgb',\n    class_mode='categorical',\n    subset='validation')","metadata":{"id":"ntMj7ynLfJKG","execution":{"iopub.status.busy":"2021-11-03T01:31:25.677312Z","iopub.execute_input":"2021-11-03T01:31:25.677652Z","iopub.status.idle":"2021-11-03T01:31:25.892516Z","shell.execute_reply.started":"2021-11-03T01:31:25.677614Z","shell.execute_reply":"2021-11-03T01:31:25.891648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_reduced = get_model(img_shape, 4)\n# model_reduced = get_resnet_model(img_shape, 4)\nmodel_reduced.summary()","metadata":{"id":"u1U8cW7PlLj7","execution":{"iopub.status.busy":"2021-11-03T01:31:25.893979Z","iopub.execute_input":"2021-11-03T01:31:25.894314Z","iopub.status.idle":"2021-11-03T01:31:25.950971Z","shell.execute_reply.started":"2021-11-03T01:31:25.894279Z","shell.execute_reply":"2021-11-03T01:31:25.95002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\ntime_callback = TimingCallback()\nmodel_reduced.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\nhistory_reduced = model_reduced.fit(train_generator,\n                              epochs=epoch_number,\n                              steps_per_epoch=train_generator.n//train_generator.batch_size,\n                              validation_data=validation_generator,\n                              validation_steps=validation_generator.n//validation_generator.batch_size,\n                              callbacks = [time_callback])","metadata":{"id":"Wxxks7sJmCKj","execution":{"iopub.status.busy":"2021-11-03T01:31:25.952476Z","iopub.execute_input":"2021-11-03T01:31:25.952868Z","iopub.status.idle":"2021-11-03T01:34:39.556569Z","shell.execute_reply.started":"2021-11-03T01:31:25.952829Z","shell.execute_reply":"2021-11-03T01:34:39.555716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking that I got the values\nprint(history_reduced.history.keys())\nprint(history_reduced.history['loss'])\nprint(history_reduced.history['accuracy'])\nprint(history_reduced.history['val_loss'])\nprint(history_reduced.history['val_accuracy'])","metadata":{"id":"9-UKvwfamggZ","execution":{"iopub.status.busy":"2021-11-03T01:34:39.558041Z","iopub.execute_input":"2021-11-03T01:34:39.558349Z","iopub.status.idle":"2021-11-03T01:34:39.565326Z","shell.execute_reply.started":"2021-11-03T01:34:39.558321Z","shell.execute_reply":"2021-11-03T01:34:39.564492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving weights\nmodel_reduced.save_weights(path + 'reduced_weights.h5')","metadata":{"id":"WqgJ8QsTmgik","execution":{"iopub.status.busy":"2021-11-03T01:34:39.566657Z","iopub.execute_input":"2021-11-03T01:34:39.567279Z","iopub.status.idle":"2021-11-03T01:34:39.605981Z","shell.execute_reply.started":"2021-11-03T01:34:39.567243Z","shell.execute_reply":"2021-11-03T01:34:39.605189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_time = time_callback.logs\nprint(np.mean(reduced_time), reduced_time)","metadata":{"id":"c-f-DJzqmgpv","execution":{"iopub.status.busy":"2021-11-03T01:34:39.607229Z","iopub.execute_input":"2021-11-03T01:34:39.607565Z","iopub.status.idle":"2021-11-03T01:34:39.612732Z","shell.execute_reply.started":"2021-11-03T01:34:39.607528Z","shell.execute_reply":"2021-11-03T01:34:39.611755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting\nfig, (ax1, ax2) = plt.subplots(1, 2, sharex=True, figsize=(25, 10))\n\nax1.plot(history_reduced.history['accuracy'])\nax1.plot(history_reduced.history['val_accuracy'])\nax1.set_title('Accuracy over epochs')\nax1.set(xlabel='Epoch', ylabel='Accuracy')\nax1.grid()\nax1.legend(['Train', 'Validation'], loc='lower right')\n\nax2.plot(history_reduced.history['loss'])\nax2.plot(history_reduced.history['val_loss'])\nax2.set_title('Loss over epochs')\nax2.set(xlabel='Epoch', ylabel='Loss')\nax2.grid()\nax2.legend(['Train', 'Validation'], loc='upper right')\n\n\nplt.show()\nfig.savefig(path + 'Loss and Accuracy over Epochs (Reduced).png')","metadata":{"id":"N-hZ464On3Lj","execution":{"iopub.status.busy":"2021-11-03T01:34:39.614641Z","iopub.execute_input":"2021-11-03T01:34:39.615Z","iopub.status.idle":"2021-11-03T01:34:40.08279Z","shell.execute_reply.started":"2021-11-03T01:34:39.614966Z","shell.execute_reply":"2021-11-03T01:34:40.081995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Time difference**\n---\n","metadata":{"id":"-X7zSMCgtiGg"}},{"cell_type":"code","source":"print(np.mean(base_time))\nprint(np.mean(reduced_time))","metadata":{"id":"H6l9h57OtlnT","execution":{"iopub.status.busy":"2021-11-03T01:34:40.084045Z","iopub.execute_input":"2021-11-03T01:34:40.084369Z","iopub.status.idle":"2021-11-03T01:34:40.091577Z","shell.execute_reply.started":"2021-11-03T01:34:40.084335Z","shell.execute_reply":"2021-11-03T01:34:40.090651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**To-Do:**\n---","metadata":{"id":"2CEdoQ5cfQ2A"}},{"cell_type":"markdown","source":"* og_dataset, reduced_dataset (less number of data, hard code the time for LSH for each image)\n* Test with both datasets (compare time)\n* Stopping time based on accuracy > 98%\n* Streaming data\n* Compare with different data reduction methods\n\nOther datasets: (feel free to add datasets here)\n* cifar10\n* stanford dataset?\n* pandaset","metadata":{"id":"6YZg0lTEf7IL"}}]}